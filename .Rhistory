devtools::document()
?bootstrap_conf_intervals
library(p1)
set.seed(123)  # Setting seed for reproducibility
n <- 200
p <- 2
@@ -117,4 +297,11 @@ ci <- bootstrap_conf_intervals(X, y)
print(ci)
n <- 200
p <- 2
ci <- bootstrap_conf_intervals(X, y)
print(ci)
set.seed(123)  # Setting seed for reproducibility
n <- 200
p <- 2
X <- matrix(rnorm(n * p), ncol = p)
true_beta <- c(1, -0.5)
pi <- 1 / (1 + exp(-X %*% true_beta))
y <- rbinom(n, 1, pi)
beta_hat <- logistic_regression(X, y)
print(beta_hat)
ci <- bootstrap_conf_intervals(X, y)
print(ci)
library("p1")
set.seed(123)  # Setting seed for reproducibility
n <- 200
p <- 2
X <- matrix(rnorm(n * p), ncol = p)
true_beta <- c(1, -0.5)
pi <- 1 / (1 + exp(-X %*% true_beta))
y <- rbinom(n, 1, pi)
beta_hat <- logistic_regression(X, y)
print(beta_hat)
ci <- bootstrap_conf_intervals(X, y)
print(ci)
#' This function calculates bootstrap confidence intervals for logistic regression coefficients.
#'
#' @param X A matrix of predictors.
#' @param y A binary response variable.
#' @param alpha Significance level for the confidence intervals.
#' @param n_bootstraps Number of bootstrap samples.
#' @return A matrix of bootstrap confidence intervals for each coefficient.
#' @export
bootstrap_conf_intervals = function(X, y, alpha = 0.05, n_bootstraps = 20) {
n = nrow(X)
p = ncol(X)
# Initialize an empty matrix to store bootstrap samples
b_samples = matrix(0, p, n_bootstraps)
# Perform bootstrap sampling
set.seed(100)  # Set seed for reproducibility
for (b in 1:n_bootstraps) {
# Sample with replacement
b_indices = sample(1:n, n, replace = TRUE)
b_X = X[b_indices,]
b_y = y[b_indices]
b_samples[, b] = logistic_regression(b_X, b_y)
}
# Compute quantiles for confidence intervals
lower = apply(b_samples, 1, quantile, 1-alpha)
upper = apply(b_samples, 1, quantile, alpha)
ci = cbind(lower, upper)
return(ci)
}
set.seed(123)  # Setting seed for reproducibility
n <- 200
p <- 2
X <- matrix(rnorm(n * p), ncol = p)
true_beta <- c(1, -0.5)
pi <- 1 / (1 + exp(-X %*% true_beta))
y <- rbinom(n, 1, pi)
beta_hat <- logistic_regression(X, y)
print(beta_hat)
ci <- bootstrap_conf_intervals(X, y)
print(ci)
devtools::document()
rm(list = c("bootstrap_conf_intervals"))
devtools::document()
?bootstrap_conf_intervals
library(p1)
set.seed(123)  # Setting seed for reproducibility
n <- 200
p <- 2
X <- matrix(rnorm(n * p), ncol = p)
true_beta <- c(1, -0.5)
pi <- 1 / (1 + exp(-X %*% true_beta))
y <- rbinom(n, 1, pi)
beta_hat <- logistic_regression(X, y)
print(beta_hat)
ci <- bootstrap_conf_intervals(X, y)
print(ci)
devtools::document()
library(p1)
set.seed(123)  # Setting seed for reproducibility
n <- 200
p <- 2
X <- matrix(rnorm(n * p), ncol = p)
true_beta <- c(1, -0.5)
pi <- 1 / (1 + exp(-X %*% true_beta))
y <- rbinom(n, 1, pi)
beta_hat <- logistic_regression(X, y)
print(beta_hat)
ci <- bootstrap_conf_intervals(X, y)
print(ci)
plot_logistic_curve(X, beta_hat, y)
devtools::document()
library(p1)
Sys.which("make")
devtools::check(document = FALSE)
pkgbuild::check_build_tools(debug = TRUE)
library(p1)
devtools::check(document = FALSE)
library(p1)
library(p1)
devtools::document()
devtools::document()
library(p1)
devtools::document()
library(p1)
#' Diagnostic Odds Ratio
#'
#' Calculates the diagnostic odds ratio based on the confusion matrix.
#'
#' @param X Matrix of predictors
#' @param y Binary response variable (0 or 1)
#' @param beta_hat Coefficient vector
#' @param cut Cut off value
#' @return Diagnostic Odds Ratio
#' @export
Diagnostic_Odds_ratio = function(X, y, beta_hat, cut = 0.5){
yhat = (1/(1+exp(-X%*%beta_hat)) > 0.5)*1
tp = sum((yhat==1)&(y==1))
fp = sum((yhat==0)&(y==1))
tn = sum((yhat==0)&(y==0))
fn = sum((yhat==1)&(y==0))
Diagnostic_Odds_ratio = (Sensitivity(X,y,beta_hat) / False_Discovery_Rate(X,y,beta_hat)) / (False_Discovery_Rate(X,y,beta_hat)/ Specificity(X,y,beta_hat))
return(Diagnostic_Odds_ratio)
}
set.seed(123)  # Setting seed for reproducibility
n <- 200
p <- 2
X <- matrix(rnorm(n * p), ncol = p)
true_beta <- c(1, -0.5)
pi <- 1 / (1 + exp(-X %*% true_beta))
y <- rbinom(n, 1, pi)
beta_hat <- logistic_regression(X, y)
print(beta_hat)
ci <- bootstrap_conf_intervals(X, y)
print(ci)
plot_logistic_curve(X, beta_hat, y)
confusion_matrix(X, y, beta_hat)
Prevalence(X, y, beta_hat)
Accuracy(X, y, beta_hat)
Sensitivity(X, y, beta_hat)
Specificity(X, y, beta_hat)
False_Discovery_Rate(X, y, beta_hat)
Diagnostic_Odds_ratio(X, y, beta_hat)
prevalencegrid(X, y, beta_hat)
?Accuracy
?p1
?Accuracy
?Con_in
pkgdown
?pkgdown
library("pkgdown")
devtools::install_github("hadley/pkgdown"))
devtools::install_github("hadley/pkgdown")
devtools::install_github("hadley/p1")
rmarkdown::render()
devtools::install_github("hadley/pkgdown")
rmarkdown::render("README.Rmd")
devtools::install_github("hadley/pkgdown")
sessionInfo()
install.packages(c("xfun", "knitr", "rmarkdown"))
install.packages(c("xfun", "knitr", "rmarkdown"))
set.seed(123)  # Setting seed for reproducibility
n =200
p = 2
X = matrix(rnorm(n * p), ncol = p)
true_beta = c(1, -0.5)
pi = 1 / (1 + exp(-X %*% true_beta))
y = rbinom(n, 1, pi)
beta_hat = logistic_regression(X, y)
library(p1)
set.seed(123)  # Setting seed for reproducibility
n =200
p = 2
X = matrix(rnorm(n * p), ncol = p)
true_beta = c(1, -0.5)
pi = 1 / (1 + exp(-X %*% true_beta))
y = rbinom(n, 1, pi)
beta_hat = logistic_regression(X, y)
bootstrap_conf_intervals(X, y)
plot_logistic_curve(X, beta_hat, y)
confusion_matrix(X, y, beta_hat)
Prevalence(X, y, beta_hat)
Accuracy(X, y, beta_hat)
Sensitivity(X, y, beta_hat)
Specificity(X, y, beta_hat)
False_Discovery_Rate(X, y, beta_hat)
Diagnostic_Odds_ratio(X, y, beta_hat)
prevalencegrid(X, y, beta_hat)
data=read.csv("expenses.csv")
data=read.csv("expenses.csv")
data = read.csv("expenses.csv")
library(p1)
set.seed(123)  # Setting seed for reproducibility
n =200
p = 2
X = matrix(rnorm(n * p), ncol = p)
true_beta = c(1, -0.5)
pi = 1 / (1 + exp(-X %*% true_beta))
y = rbinom(n, 1, pi)
beta_hat = logistic_regression(X, y)
bootstrap_conf_intervals(X, y)
plot_logistic_curve(X, beta_hat, y)
confusion_matrix(X, y, beta_hat)
Prevalence(X, y, beta_hat)
Accuracy(X, y, beta_hat)
Sensitivity(X, y, beta_hat)
Specificity(X, y, beta_hat)
False_Discovery_Rate(X, y, beta_hat)
Diagnostic_Odds_ratio(X, y, beta_hat)
prevalencegrid(X, y, beta_hat)
library(readr)
expenses <- read_csv("expenses.csv")
View(expenses)
data = read.csv("expenses.csv")
data=expenses
#data = read.csv("expenses.csv")
data=expenses
X = matrix(data$bmi, ncol = 1)
y=data$charges
beta_hat = logistic_regression(X, y)
#data = read.csv("expenses.csv")
data=expenses
X = matrix(data$bmi, ncol = 1)
y=data$charges
beta_hat = logistic_regression(X, y)
#data = read.csv("expenses.csv")
data=expenses
X = matrix(data$bmi, ncol = 1)
y=data$charges
if (any(is.na(X), is.infinite(X), is.na(y), is.infinite(y))) {
stop("Data contains NA or Inf.")
}
# Define initial_beta
initial_beta <- rep(0, ncol(X))
beta_hat = logistic_regression(X, y)
X <- scale(X)
data=expenses
X = matrix(data$bmi, ncol = 1)
X <- scale(X)
y=data$charges
if (any(is.na(X), is.infinite(X), is.na(y), is.infinite(y))) {
stop("Data contains NA or Inf.")
}
initial_beta <- rep(0, ncol(X))
beta_hat = logistic_regression(X, y)
test_model <- glm(y ~ X, family = binomial())
#data = read.csv("expenses.csv")
data = expenses
# Prepare the predictor matrix X (using 'bmi' as the predictor)
X = matrix(data$bmi, ncol = 1)
X <- scale(X)  # Standardizing X
# Ensure that y is binary. This step might need adjustment.
y = ifelse(data$charges > median(data$charges), 1, 0)
# Check for NA or Inf values in X and y
if (any(is.na(X), is.infinite(X), is.na(y), is.infinite(y))) {
stop("Data contains NA or Inf.")
}
# Logistic Regression and subsequent analyses
initial_beta <- rep(0, ncol(X))
beta_hat = logistic_regression(X, y)
print(beta_hat)
ci = bootstrap_conf_intervals(X, y)
#data = read.csv("expenses.csv")
data = expenses
# Prepare the predictor matrix X (using 'bmi' as the predictor)
X = matrix(data$bmi, ncol = 1)
X <- scale(X)  # Standardizing X
# Ensure that y is binary. This step might need adjustment.
y = ifelse(data$charges > median(data$charges), 1, 0)
# Check for NA or Inf values in X and y
if (any(is.na(X), is.infinite(X), is.na(y), is.infinite(y))) {
stop("Data contains NA or Inf.")
}
# Logistic Regression and subsequent analyses
initial_beta <- rep(0, ncol(X))
beta_hat = logistic_regression(X, y)
print(beta_hat)
#ci = bootstrap_conf_intervals(X, y)
#print(ci)
plot_logistic_curve(X, beta_hat, y)
print(confusion_matrix(X, y, beta_hat))
print(Prevalence(X, y, beta_hat))
print(Accuracy(X, y, beta_hat))
print(Sensitivity(X, y, beta_hat))
print(Specificity(X, y, beta_hat))
print(False_Discovery_Rate(X, y, beta_hat))
print(Diagnostic_Odds_ratio(X, y, beta_hat))
pg = prevalencegrid(X, y, beta_hat)
print(pg)
library(readr)
expenses <- read_csv("expenses.csv")
View(expenses)
data = read.csv("F:/Fall 2023 AU/R Programming for Data Science/Practise/p1/expenses.csv")
#data = expenses
# Prepare the predictor matrix X (using 'bmi' as the predictor)
X = matrix(data$bmi, ncol = 1)
X <- scale(X)  # Standardizing X
# Ensure that y is binary. This step might need adjustment.
y = ifelse(data$charges > median(data$charges), 1, 0)
# Check for NA or Inf values in X and y
if (any(is.na(X), is.infinite(X), is.na(y), is.infinite(y))) {
stop("Data contains NA or Inf.")
}
# Logistic Regression and subsequent analyses
initial_beta <- rep(0, ncol(X))
beta_hat = logistic_regression(X, y)
print(beta_hat)
#ci = bootstrap_conf_intervals(X, y)
#print(ci)
plot_logistic_curve(X, beta_hat, y)
print(confusion_matrix(X, y, beta_hat))
print(Prevalence(X, y, beta_hat))
print(Accuracy(X, y, beta_hat))
print(Sensitivity(X, y, beta_hat))
print(Specificity(X, y, beta_hat))
print(False_Discovery_Rate(X, y, beta_hat))
print(Diagnostic_Odds_ratio(X, y, beta_hat))
pg = prevalencegrid(X, y, beta_hat)
print(pg)
devtools::build_vignettes()
